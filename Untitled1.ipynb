{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DocoptExit",
     "evalue": "Usage:\n    edgar.py download index [options]\n    edgar.py download 10k [options]\n    edgar.py extract mda [options]\nOptions:\n    --index-dir=<file>          Directory to save index files [default: ./index]\n    --index-10k-path=<file>     CSV file to store 10k indices [default: ./index.10k.csv]\n    --10k-dir=<file>            Directory to save 10k files [default: ./form10k]\n    --mda-dir=<file>            Directory to save mda files [default: ./mda]\n    --year-start=<int>          Starting year for download index [default: 2016]\n    --year-end=<int>            Ending year for download index [default: 2016]",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mDocoptExit\u001b[0m\u001b[1;31m:\u001b[0m Usage:\n    edgar.py download index [options]\n    edgar.py download 10k [options]\n    edgar.py extract mda [options]\nOptions:\n    --index-dir=<file>          Directory to save index files [default: ./index]\n    --index-10k-path=<file>     CSV file to store 10k indices [default: ./index.10k.csv]\n    --10k-dir=<file>            Directory to save 10k files [default: ./form10k]\n    --mda-dir=<file>            Directory to save mda files [default: ./mda]\n    --year-start=<int>          Starting year for download index [default: 2016]\n    --year-end=<int>            Ending year for download index [default: 2016]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Edgar 10k MDA \n",
    "Usage:\n",
    "    edgar.py download index [options]\n",
    "    edgar.py download 10k [options]\n",
    "    edgar.py extract mda [options]\n",
    "Options:\n",
    "    --index-dir=<file>          Directory to save index files [default: ./index]\n",
    "    --index-10k-path=<file>     CSV file to store 10k indices [default: ./index.10k.csv]\n",
    "    --10k-dir=<file>            Directory to save 10k files [default: ./form10k]\n",
    "    --mda-dir=<file>            Directory to save mda files [default: ./mda]\n",
    "    --year-start=<int>          Starting year for download index [default: 2016]\n",
    "    --year-end=<int>            Ending year for download index [default: 2016]\n",
    "\"\"\"\n",
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import namedtuple\n",
    "from glob import glob\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docopt import docopt\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEC_GOV_URL = 'https://www.sec.gov/Archives'\n",
    "FORM_INDEX_URL = os.path.join(\n",
    "    SEC_GOV_URL, 'edgar', 'full-index', '{}', 'QTR{}', 'form.idx')\n",
    "IndexRecord = namedtuple(\n",
    "    \"IndexRecord\", [\"form_type\", \"company_name\", \"cik\", \"date_filed\", \"filename\"])\n",
    "\n",
    "\n",
    "def download_and_extract_index(opt):\n",
    "    index_dir = opt[\"--index-dir\"]\n",
    "    if not os.path.exists(index_dir):\n",
    "        os.makedirs(index_dir)\n",
    "\n",
    "    year_start = int(opt[\"--year-start\"])\n",
    "    year_end = int(opt[\"--year-end\"])\n",
    "\n",
    "    for year, qtr in itertools.product(range(year_start, year_end+1), range(1, 5)):\n",
    "\n",
    "        index_url = FORM_INDEX_URL.format(year, qtr)\n",
    "        try:\n",
    "            print(\"request index - {}\".format(index_url))\n",
    "            res = requests.get(index_url)\n",
    "            form_idx = \"year{}_qtr{}.index\".format(year, qtr)\n",
    "            form_idx_path = os.path.join(index_dir, form_idx)\n",
    "\n",
    "            print(\"writing index to {}\".format(form_idx_path))\n",
    "            with open(form_idx_path, 'w') as fout:\n",
    "                fout.write(res.text)\n",
    "        except:\n",
    "            print(\"download index failed - {}\".format(index_url))\n",
    "\n",
    "    def parse_row_to_record(row, fields_begin):\n",
    "        record = []\n",
    "\n",
    "        for begin, end in zip(fields_begin[:], fields_begin[1:] + [len(row)]):\n",
    "            field = row[begin:end].rstrip()\n",
    "            field = field.strip('\\\"')\n",
    "            record.append(field)\n",
    "\n",
    "        return record\n",
    "\n",
    "    records = []\n",
    "    for index_file in sorted(glob(os.path.join(index_dir, \"*.index\"))):\n",
    "        print(\"Extracting 10k records from index {}\".format(index_file))\n",
    "\n",
    "        with open(index_file, 'r') as fin:\n",
    "            # If arrived at 10-K section of forms\n",
    "            arrived = False\n",
    "\n",
    "            for row in fin.readlines():\n",
    "                if row.startswith(\"Form Type\"):\n",
    "                    fields_begin = [row.find(\"Form Type\"),\n",
    "                                    row.find(\"Company Name\"),\n",
    "                                    row.find('CIK'),\n",
    "                                    row.find('Date Filed'),\n",
    "                                    row.find(\"File Name\")]\n",
    "\n",
    "                elif row.startswith(\"10-K \"):\n",
    "                    arrived = True\n",
    "                    rec = parse_row_to_record(row, fields_begin)\n",
    "                    records.append(IndexRecord(*rec))\n",
    "\n",
    "                elif arrived == True:\n",
    "                    break\n",
    "\n",
    "    index_10k_path = opt[\"--index-10k-path\"]\n",
    "    with open(index_10k_path, 'w') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',',\n",
    "                            quotechar='\\\"', quoting=csv.QUOTE_ALL)\n",
    "        for rec in records:\n",
    "            writer.writerow(tuple(rec))\n",
    "\n",
    "\n",
    "def download_10k(opt):\n",
    "    \"\"\"Downloads 10k HTML and saves only text \n",
    "    \"\"\"\n",
    "    index_10k_path = opt[\"--index-10k-path\"]\n",
    "    assert os.path.exists(index_10k_path)\n",
    "    form10k_dir = opt[\"--10k-dir\"]\n",
    "    if not os.path.exists(form10k_dir):\n",
    "        os.makedirs(form10k_dir)\n",
    "\n",
    "    with open(index_10k_path, 'r') as fin:\n",
    "        reader = csv.reader(\n",
    "            fin, delimiter=',', quotechar='\\\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "        for row in reader:\n",
    "            _, _, _, _, filename = row\n",
    "            url = os.path.join(SEC_GOV_URL, filename).replace(\n",
    "                \"\\\\\", \"/\")\n",
    "            print('request 10k html - {}'.format(url))\n",
    "\n",
    "            try:\n",
    "                res = requests.get(url)\n",
    "                soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "                text = soup.get_text(\"\\n\")\n",
    "                fname = '_'.join(url.split('/')[-2:])\n",
    "                text_path = os.path.join(form10k_dir, fname)\n",
    "                print(\"writing 10k text to {}\".format(text_path))\n",
    "                with open(text_path, 'w') as fout:\n",
    "                    fout.write(text)\n",
    "            except Exception as e:\n",
    "                print(\"download 10k failed - {} - {}\".format(url, e))\n",
    "\n",
    "\n",
    "def extract_mda(opt):\n",
    "    form10k_dir = opt[\"--10k-dir\"]\n",
    "    assert os.path.exists(form10k_dir)\n",
    "    mda_dir = opt[\"--mda-dir\"]\n",
    "    if not os.path.exists(mda_dir):\n",
    "        os.makedirs(mda_dir)\n",
    "\n",
    "    for form10k_file in tqdm(sorted(glob(os.path.join(form10k_dir, \"*.txt\")))):\n",
    "        print(\"extracting mda from form10k file {}\".format(form10k_file))\n",
    "\n",
    "        # Read form 10k\n",
    "        with open(form10k_file, 'r') as fin:\n",
    "            text = fin.read()\n",
    "\n",
    "        # Normalize\n",
    "        text = normalize_text(text)\n",
    "\n",
    "        # Find MDA section\n",
    "        mda, end = parse_mda(text)\n",
    "        # Parse second time if first parse results in index\n",
    "        if mda and len(mda.encode('utf-8')) < 1000:\n",
    "            mda, _ = parse_mda(text, start=end)\n",
    "\n",
    "        if mda:\n",
    "            filename = os.path.basename(form10k_file)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            mda_path = os.path.join(mda_dir, name + \".mda\")\n",
    "            print(\"writing mda to {}\".format(mda_path))\n",
    "            with open(mda_path, 'w') as fout:\n",
    "                fout.write(mda)\n",
    "        else:\n",
    "            print(\"extract mda failed - {}\".format(form10k_file))\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Nomralize Text\n",
    "    \"\"\"\n",
    "    text = unicodedata.normalize(\"NFKD\", text)  # Normalize\n",
    "    text = '\\n'.join(\n",
    "        text.splitlines())  # Let python take care of unicode break lines\n",
    "\n",
    "    # Convert to upper\n",
    "    text = text.upper()  # Convert to upper\n",
    "\n",
    "    # Take care of breaklines & whitespaces combinations due to beautifulsoup parsing\n",
    "    text = re.sub(r'[ ]+\\n', '\\n', text)\n",
    "    text = re.sub(r'\\n[ ]+', '\\n', text)\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # To find MDA section, reformat item headers\n",
    "    text = text.replace('\\n.\\n', '.\\n')  # Move Period to beginning\n",
    "\n",
    "    text = text.replace('\\nI\\nTEM', '\\nITEM')\n",
    "    text = text.replace('\\nITEM\\n', '\\nITEM ')\n",
    "    text = text.replace('\\nITEM  ', '\\nITEM ')\n",
    "\n",
    "    text = text.replace(':\\n', '.\\n')\n",
    "\n",
    "    # Math symbols for clearer looks\n",
    "    text = text.replace('$\\n', '$')\n",
    "    text = text.replace('\\n%', '%')\n",
    "\n",
    "    # Reformat\n",
    "    text = text.replace('\\n', '\\n\\n')  # Reformat by additional breakline\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def parse_mda(text, start=0):\n",
    "    debug = False\n",
    "    \"\"\"Parse normalized text \n",
    "    \"\"\"\n",
    "\n",
    "    mda = \"\"\n",
    "    end = 0\n",
    "    \"\"\"\n",
    "        Parsing Rules\n",
    "    \"\"\"\n",
    "\n",
    "    # Define start & end signal for parsing\n",
    "    item7_begins = [\n",
    "        '\\nITEM 7.', '\\nITEM 7 â€“', '\\nITEM 7:', '\\nITEM 7 ', '\\nITEM 7\\n'\n",
    "    ]\n",
    "    item7_ends = ['\\nITEM 7A']\n",
    "    if start != 0:\n",
    "        item7_ends.append('\\nITEM 7')  # Case: ITEM 7A does not exist\n",
    "    item8_begins = ['\\nITEM 8']\n",
    "    \"\"\"\n",
    "        Parsing code section\n",
    "    \"\"\"\n",
    "    text = text[start:]\n",
    "\n",
    "    # Get begin\n",
    "    for item7 in item7_begins:\n",
    "        begin = text.find(item7)\n",
    "        if debug:\n",
    "            print(item7, begin)\n",
    "        if begin != -1:\n",
    "            break\n",
    "\n",
    "    if begin != -1:  # Begin found\n",
    "        for item7A in item7_ends:\n",
    "            end = text.find(item7A, begin + 1)\n",
    "            if debug:\n",
    "                print(item7A, end)\n",
    "            if end != -1:\n",
    "                break\n",
    "\n",
    "        if end == -1:  # ITEM 7A does not exist\n",
    "            for item8 in item8_begins:\n",
    "                end = text.find(item8, begin + 1)\n",
    "                if debug:\n",
    "                    print(item8, end)\n",
    "                if end != -1:\n",
    "                    break\n",
    "\n",
    "        # Get MDA\n",
    "        if end > begin:\n",
    "            mda = text[begin:end].strip()\n",
    "        else:\n",
    "            end = 0\n",
    "\n",
    "    return mda, end\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    opt = docopt(__doc__)\n",
    "    print(opt)\n",
    "    if opt[\"download\"] and opt[\"index\"]:\n",
    "        download_and_extract_index(opt)\n",
    "    elif opt[\"download\"] and opt[\"10k\"]:\n",
    "        download_10k(opt)\n",
    "    elif opt[\"extract\"] and opt[\"mda\"]:\n",
    "        extract_mda(opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
